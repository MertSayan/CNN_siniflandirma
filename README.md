ğŸ¦· CNN TabanlÄ± DiÅŸ FÄ±rÃ§asÄ± ve Macunu SÄ±nÄ±flandÄ±rma Projesi
Model KarÅŸÄ±laÅŸtÄ±rmasÄ±: Transfer Learning (VGG16) ve Ã–zel CNN Mimarileri
Bu projede, tamamen Ã¶zgÃ¼n olarak oluÅŸturulmuÅŸ bir gÃ¶rÃ¼ntÃ¼ veri seti Ã¼zerinde Convolutional Neural Network (CNN) tabanlÄ± sÄ±nÄ±flandÄ±rma modelleri geliÅŸtirilmiÅŸ ve performanslarÄ± karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r.

Projenin temel amacÄ±; hazÄ±r State-of-the-Art (VGG16) mimarisi ile sÄ±fÄ±rdan (from scratch) eÄŸitilen modeller arasÄ±ndaki performans farklarÄ±nÄ± gÃ¶zlemlemek, veri artÄ±rÄ±mÄ± (data augmentation) ve hiperparametre optimizasyonunun model baÅŸarÄ±sÄ±na etkisini analiz etmektir.

---

ğŸ“ Veri Seti
Kaynak: Veri seti tamamen proje kapsamÄ±nda Ã¶zgÃ¼n olarak oluÅŸturulmuÅŸtur. Ä°nternetten hazÄ±r veri seti kullanÄ±lmamÄ±ÅŸtÄ±r.

Ã‡ekim: GÃ¶rÃ¼ntÃ¼ler farklÄ± aÃ§Ä±lardan ve zeminlerden Ã§ekilerek Ã§eÅŸitlilik saÄŸlanmÄ±ÅŸtÄ±r.

Ã–n Ä°ÅŸleme: TÃ¼m gÃ¶rÃ¼ntÃ¼ler ham halinden 128x128 piksel boyutuna yeniden boyutlandÄ±rÄ±lmÄ±ÅŸ ve dataset_128 klasÃ¶rÃ¼nde toplanmÄ±ÅŸtÄ±r. Daha sonra eÄŸitim, doÄŸrulama ve test setlerine ayrÄ±lmÄ±ÅŸtÄ±r.

SÄ±nÄ±flar
DiÅŸ FÄ±rÃ§asÄ± (dis_fircasi)

DiÅŸ Macunu (dis_macunu)

dataset_split/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ dis_fircasi/
â”‚   â””â”€â”€ dis_macunu/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ dis_fircasi/
â”‚   â””â”€â”€ dis_macunu/
â””â”€â”€ test/
    â”œâ”€â”€ dis_fircasi/
    â””â”€â”€ dis_macunu/

---

ğŸ§ª Model 1 â€“ Transfer Learning (State-of-the-Art)
Bu aÅŸamada, ImageNet yarÄ±ÅŸmasÄ±nda kendini kanÄ±tlamÄ±ÅŸ VGG16 mimarisi kullanÄ±lmÄ±ÅŸtÄ±r.

Mimari: VGG16 (ImageNet aÄŸÄ±rlÄ±klarÄ± ile).

Strateji: include_top=False yapÄ±larak sÄ±nÄ±flandÄ±rÄ±cÄ± katmanlarÄ± atÄ±lmÄ±ÅŸ, konvolÃ¼syon katmanlarÄ± dondurulmuÅŸtur (Freeze).

Eklenen Katmanlar: Flatten + Dense(256) + Dropout(0.5) + Output(Softmax).

AmaÃ§: Ã‡ok az veriyle bile, Ã¶nceden Ã¶ÄŸrenilmiÅŸ Ã¶zelliklerin (kenar, doku bilgisi) kullanÄ±larak yÃ¼ksek baÅŸarÄ± elde edilmesi.

Notebook: Model1.ipynb

---

ğŸ§ª Model 2 â€“ Basit CNN (Baseline Model)
SÄ±fÄ±rdan tasarlanan (from scratch), veri artÄ±rÄ±mÄ± uygulanmamÄ±ÅŸ temel modeldir.

Mimari: 2 Bloklu KonvolÃ¼syon YapÄ±sÄ± (32 ve 64 filtre).

Veri Ä°ÅŸleme: Sadece Rescale (1./255). Veri artÄ±rÄ±mÄ± yoktur.

Eksiklik: Veri artÄ±rÄ±mÄ± olmadÄ±ÄŸÄ± iÃ§in model ezberlemeye (overfitting) daha meyillidir ve genelleme yeteneÄŸi kÄ±sÄ±tlÄ±dÄ±r.

Notebook: Model2.ipynb

---

ğŸ§ª Model 3 â€“ GeliÅŸtirilmiÅŸ CNN (Optimize EdilmiÅŸ)
Model 2'nin eksikliklerini gidermek ve performansÄ± Transfer Learning seviyesine yaklaÅŸtÄ±rmak iÃ§in tasarlanmÄ±ÅŸtÄ±r.

GeliÅŸtirmeler:

Derinlik ArtÄ±ÅŸÄ±: Katman sayÄ±sÄ± artÄ±rÄ±larak 3. Blok (128 Filtre) eklenmiÅŸtir.

Online Veri ArtÄ±rÄ±mÄ± (Data Augmentation): Rotation, Width Shift, Height Shift, Horizontal Flip teknikleri ile veri seti eÄŸitim sÄ±rasÄ±nda sanal olarak Ã§oÄŸaltÄ±lmÄ±ÅŸtÄ±r.

Kademeli Dropout: Modelin kararlÄ±lÄ±ÄŸÄ±nÄ± artÄ±rmak iÃ§in katman aralarÄ±na 0.1, 0.2 ve 0.3 oranlarÄ±nda dropout eklenmiÅŸtir.

AmaÃ§: Veri setini zenginleÅŸtirerek ve mimariyi derinleÅŸtirerek modelin "ezberlemesini" deÄŸil "Ã¶ÄŸrenmesini" saÄŸlamak.

Notebook: Model3.ipynb

---

<img width="754" height="400" alt="image" src="https://github.com/user-attachments/assets/16f8880c-65c3-4b99-95fb-72fc72eb95e3" />

---

Ã‡Ä±karÄ±mlar
Transfer Learning'in GÃ¼cÃ¼: KÃ¼Ã§Ã¼k veri setlerinde VGG16 gibi gÃ¼Ã§lÃ¼ modeller, sÄ±fÄ±rdan eÄŸitime gÃ¶re Ã§ok daha hÄ±zlÄ± ve yÃ¼ksek sonuÃ§ vermektedir.

Veri ArtÄ±rÄ±mÄ±nÄ±n Ã–nemi: Model 3'te uygulanan veri artÄ±rÄ±mÄ± (Augmentation), modelin baÅŸarÄ±sÄ±nÄ± Model 2'ye gÃ¶re belirgin ÅŸekilde artÄ±rmÄ±ÅŸtÄ±r.

Mimari DerinliÄŸi: Filtre sayÄ±sÄ±nÄ± 128'e Ã§Ä±karmak ve katman eklemek, modelin nesne detaylarÄ±nÄ± daha iyi Ã¶ÄŸrenmesini saÄŸlamÄ±ÅŸtÄ±r.

---

ğŸ›  KullanÄ±lan Teknolojiler
Dil: Python

KÃ¼tÃ¼phaneler: TensorFlow, Keras, NumPy, Matplotlib, PIL

Ortam: Google Colab (GPU HÄ±zlandÄ±rma ile)

GÃ¶rselleÅŸtirme: Matplotlib ile Accuracy/Loss grafikleri ve Confusion Matrix analizleri.

---

ğŸ¯ Proje Ã–zeti
Bu Ã§alÄ±ÅŸma; gÃ¶rÃ¼ntÃ¼ iÅŸleme projelerinde Transfer Learning kullanÄ±mÄ±nÄ±n avantajlarÄ±nÄ± ve kendi tasarladÄ±ÄŸÄ±mÄ±z modellerde 
hiperparametre optimizasyonunun (Ã¶zellikle veri artÄ±rÄ±mÄ± ve dropout) ne kadar kritik olduÄŸunu deneysel verilerle ortaya koymuÅŸtur.
